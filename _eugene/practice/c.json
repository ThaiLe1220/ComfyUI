{
  "last_node_id": 57,
  "last_link_id": 54,
  "nodes": [
    {
      "id": 19,
      "type": "UpscaleModelLoader",
      "pos": [
        2410,
        -2070
      ],
      "size": {
        "0": 280,
        "1": 60
      },
      "flags": {
        "collapsed": true
      },
      "order": 0,
      "mode": 4,
      "outputs": [
        {
          "name": "UPSCALE_MODEL",
          "type": "UPSCALE_MODEL",
          "links": [
            19
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "UpscaleModelLoader"
      },
      "widgets_values": [
        "RealESRGAN_x2.pth"
      ]
    },
    {
      "id": 29,
      "type": "CR Text",
      "pos": [
        -550,
        -770
      ],
      "size": {
        "0": 210,
        "1": 190
      },
      "flags": {},
      "order": 1,
      "mode": 4,
      "outputs": [
        {
          "name": "text",
          "type": "*",
          "links": [
            36
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "show_help",
          "type": "STRING",
          "links": [],
          "shape": 3,
          "slot_index": 1
        }
      ],
      "properties": {
        "Node name for S&R": "CR Text"
      },
      "widgets_values": [
        "----\n\nOnly output the content in {} of the content above,  don't output anything else."
      ]
    },
    {
      "id": 30,
      "type": "OllamaGenerate",
      "pos": [
        -550,
        -1010
      ],
      "size": {
        "0": 210,
        "1": 180
      },
      "flags": {},
      "order": 13,
      "mode": 4,
      "inputs": [
        {
          "name": "prompt",
          "type": "STRING",
          "link": 32,
          "widget": {
            "name": "prompt"
          }
        }
      ],
      "outputs": [
        {
          "name": "response",
          "type": "STRING",
          "links": [
            35
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "OllamaGenerate"
      },
      "widgets_values": [
        "What is Art?",
        "enable",
        "http://127.0.0.1:11434",
        "llama3.1:latest",
        1105945924061300,
        "randomize",
        "0"
      ]
    },
    {
      "id": 33,
      "type": "ConcatText_Zho",
      "pos": [
        -280,
        -880
      ],
      "size": {
        "0": 210,
        "1": 50
      },
      "flags": {},
      "order": 18,
      "mode": 4,
      "inputs": [
        {
          "name": "text_1",
          "type": "STRING",
          "link": 35,
          "widget": {
            "name": "text_1"
          }
        },
        {
          "name": "text_2",
          "type": "STRING",
          "link": 36,
          "widget": {
            "name": "text_2"
          }
        }
      ],
      "outputs": [
        {
          "name": "text",
          "type": "STRING",
          "links": [
            34
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "ConcatText_Zho"
      },
      "widgets_values": [
        "",
        ""
      ]
    },
    {
      "id": 34,
      "type": "ConcatText_Zho",
      "pos": [
        -540,
        -1110
      ],
      "size": {
        "0": 210,
        "1": 50
      },
      "flags": {},
      "order": 10,
      "mode": 4,
      "inputs": [
        {
          "name": "text_1",
          "type": "STRING",
          "link": 40,
          "widget": {
            "name": "text_1"
          }
        },
        {
          "name": "text_2",
          "type": "STRING",
          "link": 38,
          "widget": {
            "name": "text_2"
          }
        }
      ],
      "outputs": [
        {
          "name": "text",
          "type": "STRING",
          "links": [
            32
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "ConcatText_Zho"
      },
      "widgets_values": [
        "",
        ""
      ]
    },
    {
      "id": 21,
      "type": "VAEEncode",
      "pos": [
        2530,
        -2030
      ],
      "size": {
        "0": 210,
        "1": 50
      },
      "flags": {
        "collapsed": true
      },
      "order": 21,
      "mode": 4,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 21
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 23
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            30
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEEncode"
      }
    },
    {
      "id": 20,
      "type": "ImageScale",
      "pos": [
        2360,
        -2030
      ],
      "size": {
        "0": 270,
        "1": 130
      },
      "flags": {
        "collapsed": true
      },
      "order": 19,
      "mode": 4,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 20
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            21
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "ImageScale"
      },
      "widgets_values": [
        "nearest-exact",
        1024,
        1536,
        "disabled"
      ]
    },
    {
      "id": 18,
      "type": "ImageUpscaleWithModel",
      "pos": [
        2610,
        -2070
      ],
      "size": {
        "0": 250,
        "1": 50
      },
      "flags": {
        "collapsed": true
      },
      "order": 15,
      "mode": 4,
      "inputs": [
        {
          "name": "upscale_model",
          "type": "UPSCALE_MODEL",
          "link": 19
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 18
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            20
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "ImageUpscaleWithModel"
      }
    },
    {
      "id": 32,
      "type": "OllamaGenerate",
      "pos": [
        -280,
        -780
      ],
      "size": {
        "0": 210,
        "1": 180
      },
      "flags": {},
      "order": 20,
      "mode": 4,
      "inputs": [
        {
          "name": "prompt",
          "type": "STRING",
          "link": 34,
          "widget": {
            "name": "prompt"
          }
        }
      ],
      "outputs": [
        {
          "name": "response",
          "type": "STRING",
          "links": [
            43
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "OllamaGenerate"
      },
      "widgets_values": [
        "What is Art?",
        "enable",
        "http://127.0.0.1:11434",
        "llama3.1:latest",
        395271306652197,
        "randomize",
        "0"
      ]
    },
    {
      "id": 50,
      "type": "Note",
      "pos": [
        100,
        -1770
      ],
      "size": {
        "0": 600,
        "1": 70
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "{[historical scene], [old photograph from far away, blurry, front look, daily life scene], [faded colors, warm light, outdoor atmosphere]}"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 25,
      "type": "KSampler (Efficient)",
      "pos": [
        2410,
        -1930
      ],
      "size": {
        "0": 350,
        "1": 670
      },
      "flags": {
        "collapsed": false
      },
      "order": 23,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 25
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 26
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 27
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 30
        },
        {
          "name": "optional_vae",
          "type": "VAE",
          "link": 29
        },
        {
          "name": "script",
          "type": "SCRIPT",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": null,
          "shape": 3
        },
        {
          "name": "CONDITIONING+",
          "type": "CONDITIONING",
          "links": null,
          "shape": 3
        },
        {
          "name": "CONDITIONING-",
          "type": "CONDITIONING",
          "links": null,
          "shape": 3
        },
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [],
          "shape": 3,
          "slot_index": 3
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [],
          "shape": 3,
          "slot_index": 4
        },
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            31
          ],
          "shape": 3,
          "slot_index": 5
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler (Efficient)"
      },
      "widgets_values": [
        856147823513922,
        null,
        3,
        1.5,
        "dpmpp_sde",
        "karras",
        0.35000000000000003,
        "auto",
        "true"
      ],
      "color": "#223333",
      "bgcolor": "#335555",
      "shape": 1
    },
    {
      "id": 26,
      "type": "PreviewImage",
      "pos": [
        2420,
        -1210
      ],
      "size": {
        "0": 450,
        "1": 670
      },
      "flags": {
        "collapsed": false
      },
      "order": 24,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 31
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 42,
      "type": "Note",
      "pos": [
        100,
        -1870
      ],
      "size": {
        "0": 600,
        "1": 70
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "title": "244043068553244, 20, 8, euler",
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "{[historical figures, woman, old image, photo], [woman with a unclear/missing face, blurry and from far away, daily life scene, old photo with faded colors and worn edges, woman in a historical setting, front look, simple background], [old photograph, taken from the early 20th century, showing a woman's daily life, simplicity and nostalgia, warm tones]}"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 38,
      "type": "CR Text",
      "pos": [
        -890,
        -1110
      ],
      "size": {
        "0": 300,
        "1": 160
      },
      "flags": {},
      "order": 4,
      "mode": 4,
      "outputs": [
        {
          "name": "text",
          "type": "*",
          "links": [
            40
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "show_help",
          "type": "STRING",
          "links": [],
          "shape": 3,
          "slot_index": 1
        }
      ],
      "properties": {
        "Node name for S&R": "CR Text"
      },
      "widgets_values": [
        "old image, old photo, historical, front look, blurry, daily life, human"
      ]
    },
    {
      "id": 28,
      "type": "CR Text",
      "pos": [
        -900,
        -900
      ],
      "size": {
        "0": 300,
        "1": 160
      },
      "flags": {},
      "order": 5,
      "mode": 4,
      "outputs": [
        {
          "name": "text",
          "type": "*",
          "links": [
            38
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "show_help",
          "type": "STRING",
          "links": [],
          "shape": 3,
          "slot_index": 1
        }
      ],
      "properties": {
        "Node name for S&R": "CR Text"
      },
      "widgets_values": [
        "---------------------\n\nPlease create an image generation prompt in English from 30 to 50 words to fit the brief above, operate step by step:\n\nStep 1: If there are no characters in the brief, skip this step. \nList the names and genders of all the characters in the result of Step 1. \n\nStep 2: If there are no characters in the brief, skip this step. \nUse a short phrase to describe the result of Step 1. This phrase can use plurals or and, do not use any punctuation. Do not use any punctuation in this short phrase. The format is as follows:\nonly one person:\n- 1boy\n- 1girl\ntwo persons:\n- 2boys\n- 2girls\n- 1girl and 1boy\nthree or more persons:\n...\n\nStep 3: Keep the key information of the brief above, add more detail and nuance to the prompt. \n\nFormat: three-part bracket \n{[result of Step 2(if there is no explicit subject, remove this part)], [detailed features and actions of each subject from left to right, top to bottom(if there is no explicit subject, remove this part)], [scene, atmosphere, etc.]}\n\nexamplesï¼š\none person:\n- {[1girl], [souryuu asuka langley from neon genesis evangelion, rebuild of evangelion], lance of longinus, cat hat, plugsuit, pilot suit, red bodysuit, sitting, crossed legs, black eye patch, throne, looking down, from bottom, looking at viewer, outdoors, (masterpiece), (best quality), (ultra-detailed), very aesthetic, disheveled hair, perfect composition, moist skin, intricate details]}\ntwo persons:\n- {[1boy and 1girl], [Chun-Li from Street Fighter and Spider-Man from Marvel movies], [engaged in a fierce battle, dynamic fighting poses, action movie poster]}\n- {[1boy and 1girl], [K-pop male singer (left of center) with short black hair, brown eyes, white color, formal suit with satin lapel and bow tie, halfbody shot, K-pop female singer (center) with long straight black hair, dark brown eyes], [white color, formal silver dress, halfbody shot], both singers holding hands up in peace signs, bright colors, sunny background]}\nnon-human subject:\n- {[1cat], [sitting on a stone floor, looking down with a frowning expression, yellow eyes, white coat with grey markings around its face, slightly open mouth as if meowing or purring], [stone floor as the background, neutral lighting, simple composition, textured background, humorous and endearing tone]}\none person and one non-human subject:\n- {[1boy and 1cat], [boy with short black hair and brown eyes, cat sitting on a stone floor, looking down with a frowning expression, yellow eyes, white coat with grey markings around its face, slightly open mouth as if meowing or purring], [stone floor as the background, neutral lighting, simple composition, textured background, humorous and endearing tone]}\nno explicit subject:\n- {[Mighty water plunges, glistening jewels in sunlight. Surrounding greenery frames nature's spectacle. Sound roars, a symphony of life. Paint the power, beauty, and serenity of this breathtaking scene]}\n\nStep 4: Only output the content in {} of result of Step 3, don't output anything else, such as \"Here is the result:\", \"Here is the image generation prompt in English\", \"Here is the image generation prompt\" and \"Note: ...\"."
      ]
    },
    {
      "id": 31,
      "type": "DisplayText_Zho",
      "pos": [
        0,
        -1120
      ],
      "size": {
        "0": 490,
        "1": 190
      },
      "flags": {},
      "order": 22,
      "mode": 4,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "link": 43,
          "widget": {
            "name": "text"
          }
        }
      ],
      "outputs": [
        {
          "name": "text",
          "type": "STRING",
          "links": [],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "DisplayText_Zho"
      },
      "widgets_values": [
        "",
        "{[1person], [an old photograph from daily life, front view, blurry image of an elderly person or someone with a nostalgic expression, possibly holding an object or standing in front of something, simple background that doesn't distract from the subject, warm lighting that captures the essence of nostalgia and everyday moments, high level of detail and texture to bring out the emotional depth], [a quiet moment in history, capturing life as it was lived, conveying a sense of timelessness and universality]}"
      ]
    },
    {
      "id": 16,
      "type": "Note",
      "pos": [
        670,
        -1490
      ],
      "size": {
        "0": 500,
        "1": 180
      },
      "flags": {},
      "order": 6,
      "mode": 4,
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "(nsfw:1.25), (nipples:1.25), (low quality, worst quality:1.2), low-resolution, lowres, jpeg artifacts, compression artifacts, poorly drawn, downsampling, aliasing, distorted, pixelated, fake, hyper, glitch, distortion, text, watermark, signature, user name, artist name, moir pattern, blurry, glossy, ugly, twisted, excessive, exaggerated pose, exaggerated limbs, grainy, duplicate, error, beginner, overexposed, high-contrast, bad-contrast, selfie, handy, phone, embedding:badhandv4, naked, nude, deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4, deformed, distorted, disfigured:1.3, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, disgusting, amputation\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 15,
      "type": "PreviewImage",
      "pos": [
        1560,
        -1550
      ],
      "size": {
        "0": 660,
        "1": 750
      },
      "flags": {},
      "order": 14,
      "mode": 4,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 15
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 11,
      "type": "Efficient Loader",
      "pos": [
        650,
        -1220
      ],
      "size": {
        "0": 450,
        "1": 670
      },
      "flags": {
        "collapsed": false
      },
      "order": 7,
      "mode": 4,
      "inputs": [
        {
          "name": "lora_stack",
          "type": "LORA_STACK",
          "link": null
        },
        {
          "name": "cnet_stack",
          "type": "CONTROL_NET_STACK",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            10,
            25
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CONDITIONING+",
          "type": "CONDITIONING",
          "links": [
            17,
            26
          ],
          "shape": 3,
          "slot_index": 1
        },
        {
          "name": "CONDITIONING-",
          "type": "CONDITIONING",
          "links": [
            16,
            27
          ],
          "shape": 3,
          "slot_index": 2
        },
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            13
          ],
          "shape": 3,
          "slot_index": 3
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            14,
            29
          ],
          "shape": 3,
          "slot_index": 4
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": null,
          "shape": 3
        },
        {
          "name": "DEPENDENCIES",
          "type": "DEPENDENCIES",
          "links": null,
          "shape": 3,
          "slot_index": 6
        }
      ],
      "properties": {
        "Node name for S&R": "Efficient Loader"
      },
      "widgets_values": [
        "v1-5-pruned-emaonly.ckpt",
        "vae-ft-mse-840000-ema-pruned.safetensors",
        -1,
        "None",
        0.5,
        0,
        "(low quality, worst quality:1.2), low-resolution, lowres, jpeg artifacts, compression artifacts, poorly drawn, downsampling, aliasing, distorted, pixelated, fake\n\n{[low-quality, low-resolution, an photograph from daily life, front view, blurry image of people or someone with a nostalgic expression, possibly holding an object or standing in front of something, simple background that doesn't distract from the subject, warm lighting that captures the essence of nostalgia and everyday moments, high level of detail and texture to bring out the emotional depth], [capturing life as it was lived, conveying a sense of timelessness and universality]}{[low-quality, low-resolution, an photograph from daily life, front view, blurry image of people or someone with a nostalgic expression, possibly holding an object or standing in front of something, simple background that doesn't distract from the subject, warm lighting that captures the essence of nostalgia and everyday moments, high level of detail and texture to bring out the emotional depth], [capturing life as it was lived, conveying a sense of timelessness and universality]}",
        "",
        "mean",
        "A1111",
        512,
        768,
        4
      ],
      "color": "#332222",
      "bgcolor": "#553333",
      "shape": 1
    },
    {
      "id": 14,
      "type": "KSampler (Efficient)",
      "pos": [
        1150,
        -1220
      ],
      "size": {
        "0": 350,
        "1": 670
      },
      "flags": {
        "collapsed": false
      },
      "order": 11,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 10
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 17
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 16
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 13
        },
        {
          "name": "optional_vae",
          "type": "VAE",
          "link": 14
        },
        {
          "name": "script",
          "type": "SCRIPT",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": null,
          "shape": 3
        },
        {
          "name": "CONDITIONING+",
          "type": "CONDITIONING",
          "links": null,
          "shape": 3
        },
        {
          "name": "CONDITIONING-",
          "type": "CONDITIONING",
          "links": null,
          "shape": 3
        },
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [],
          "shape": 3,
          "slot_index": 3
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            23
          ],
          "shape": 3,
          "slot_index": 4
        },
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            15,
            18,
            51
          ],
          "shape": 3,
          "slot_index": 5
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler (Efficient)"
      },
      "widgets_values": [
        438404467381736,
        null,
        20,
        8,
        "dpmpp_sde",
        "karras",
        1,
        "auto",
        "true"
      ],
      "color": "#223333",
      "bgcolor": "#335555",
      "shape": 1
    },
    {
      "id": 49,
      "type": "SaveImage",
      "pos": [
        1230,
        -1560
      ],
      "size": {
        "0": 250,
        "1": 270
      },
      "flags": {
        "collapsed": true
      },
      "order": 16,
      "mode": 4,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 51,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": [
        "DEFORMED"
      ]
    },
    {
      "id": 52,
      "type": "LoadImage",
      "pos": [
        1300,
        -2870
      ],
      "size": {
        "0": 320,
        "1": 310
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            52
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "DEFORMED_00001__01 (1).png",
        "image"
      ]
    },
    {
      "id": 54,
      "type": "PreviewImage",
      "pos": [
        1770,
        -2750
      ],
      "size": {
        "0": 210,
        "1": 250
      },
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 53
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 55,
      "type": "FaceRestoreModelLoader",
      "pos": [
        1680,
        -3020
      ],
      "size": {
        "0": 320,
        "1": 60
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "outputs": [
        {
          "name": "FACERESTORE_MODEL",
          "type": "FACERESTORE_MODEL",
          "links": [
            54
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "FaceRestoreModelLoader"
      },
      "widgets_values": [
        "GFPGANx1024.pth"
      ]
    },
    {
      "id": 53,
      "type": "FaceRestoreCFWithModel",
      "pos": [
        1680,
        -2890
      ],
      "size": {
        "0": 320,
        "1": 100
      },
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "facerestore_model",
          "type": "FACERESTORE_MODEL",
          "link": 54
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 52
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            53
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "FaceRestoreCFWithModel"
      },
      "widgets_values": [
        "retinaface_resnet50",
        1
      ]
    }
  ],
  "links": [
    [
      10,
      11,
      0,
      14,
      0,
      "MODEL"
    ],
    [
      13,
      11,
      3,
      14,
      3,
      "LATENT"
    ],
    [
      14,
      11,
      4,
      14,
      4,
      "VAE"
    ],
    [
      15,
      14,
      5,
      15,
      0,
      "IMAGE"
    ],
    [
      16,
      11,
      2,
      14,
      2,
      "CONDITIONING"
    ],
    [
      17,
      11,
      1,
      14,
      1,
      "CONDITIONING"
    ],
    [
      18,
      14,
      5,
      18,
      1,
      "IMAGE"
    ],
    [
      19,
      19,
      0,
      18,
      0,
      "UPSCALE_MODEL"
    ],
    [
      20,
      18,
      0,
      20,
      0,
      "IMAGE"
    ],
    [
      21,
      20,
      0,
      21,
      0,
      "IMAGE"
    ],
    [
      23,
      14,
      4,
      21,
      1,
      "VAE"
    ],
    [
      25,
      11,
      0,
      25,
      0,
      "MODEL"
    ],
    [
      26,
      11,
      1,
      25,
      1,
      "CONDITIONING"
    ],
    [
      27,
      11,
      2,
      25,
      2,
      "CONDITIONING"
    ],
    [
      29,
      11,
      4,
      25,
      4,
      "VAE"
    ],
    [
      30,
      21,
      0,
      25,
      3,
      "LATENT"
    ],
    [
      31,
      25,
      5,
      26,
      0,
      "IMAGE"
    ],
    [
      32,
      34,
      0,
      30,
      0,
      "STRING"
    ],
    [
      34,
      33,
      0,
      32,
      0,
      "STRING"
    ],
    [
      35,
      30,
      0,
      33,
      0,
      "STRING"
    ],
    [
      36,
      29,
      0,
      33,
      1,
      "STRING"
    ],
    [
      38,
      28,
      0,
      34,
      1,
      "STRING"
    ],
    [
      40,
      38,
      0,
      34,
      0,
      "STRING"
    ],
    [
      43,
      32,
      0,
      31,
      0,
      "STRING"
    ],
    [
      51,
      14,
      5,
      49,
      0,
      "IMAGE"
    ],
    [
      52,
      52,
      0,
      53,
      1,
      "IMAGE"
    ],
    [
      53,
      53,
      0,
      54,
      0,
      "IMAGE"
    ],
    [
      54,
      55,
      0,
      53,
      0,
      "FACERESTORE_MODEL"
    ]
  ],
  "groups": [
    {
      "title": "Upscale",
      "bounding": [
        2350,
        -2140,
        530,
        1614
      ],
      "color": "#3f789e",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "Auto Prompt",
      "bounding": [
        -910,
        -1200,
        1410,
        624
      ],
      "color": "#3f789e",
      "font_size": 24,
      "locked": false
    },
    {
      "title": "Main",
      "bounding": [
        640,
        -1630,
        1590,
        1094
      ],
      "color": "#3f789e",
      "font_size": 24,
      "locked": false
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.38554328942953164,
      "offset": {
        "0": 430.62322998046875,
        "1": 3547.881591796875
      }
    }
  },
  "version": 0.4
}